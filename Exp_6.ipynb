{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw9xlr2_Hj3X",
        "outputId": "c02e503d-ecc3-4ed6-88b0-c4c9337c5088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Data :\n",
            " [[0.5 0.3]\n",
            " [0.2 0.7]\n",
            " [0.8 0.9]]\n",
            "Weighted Sum :\n",
            " [[0.56]\n",
            " [0.4 ]\n",
            " [0.92]]\n",
            "Output :\n",
            " [[0.63645254]\n",
            " [0.59868766]\n",
            " [0.71504211]]\n"
          ]
        }
      ],
      "source": [
        "# Forward Pass with Matrix Multiplication\n",
        "import numpy as np\n",
        "\n",
        "def activation(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def forwardpass(x,weights,bias):\n",
        "  weighted_sum=np.dot(x,weights)+bias\n",
        "  print(\"Weighted Sum :\\n\",weighted_sum)\n",
        "  output=activation(weighted_sum)\n",
        "  return output\n",
        "\n",
        "#input data\n",
        "x=np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
        "\n",
        "#weights\n",
        "weights=np.array([[0.8], [0.2]])\n",
        "\n",
        "#targets\n",
        "targets=np.array([[1], [0], [1]])\n",
        "\n",
        "#bias\n",
        "bias=np.array([0.1])\n",
        "\n",
        "print(\"Input Data :\\n\",x)\n",
        "\n",
        "output=forwardpass(x,weights,bias)\n",
        "print(\"Output :\\n\",output)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward Pass with Hidden Layer (Matrix Multiplication)\n",
        "\n",
        "\n",
        "def forwardpass(x,w1,w2,b1,b2):\n",
        "  #input to hidden layer\n",
        "  weighted_sum1=np.dot(x,w1)+b1\n",
        "  print(\"Weighted Sum from input layer :\\n\",weighted_sum1)\n",
        "  h_in=activation(weighted_sum1)\n",
        "  #hidden to output layer\n",
        "  weighted_sum2=np.dot(h_in,w2)+b2\n",
        "  print(\"Weighted Sum from hidden layer :\\n\",weighted_sum2)\n",
        "  h_out=activation(weighted_sum2)\n",
        "  return h_out\n",
        "\n",
        "#input data\n",
        "x=np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
        "\n",
        "#targets\n",
        "targets=np.array([[1], [0], [1]])\n",
        "\n",
        "# Weights and biases for the input layer to hidden layer\n",
        "w1= np.array([[0.8, 0.2], [0.4, 0.9]])\n",
        "b1 = np.array([0.1, 0.5])\n",
        "\n",
        "# Weights and bias for the hidden layer to output layer\n",
        "w2 = np.array([[0.3], [0.7]])\n",
        "b2= np.array([0.2])\n",
        "\n",
        "final_output=forwardpass(x,w1,w2,b1,b2)\n",
        "\n",
        "print(\"Input Data :\\n\",x)\n",
        "print(\"Output :\\n\",final_output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C4-6N1G6Iqpq",
        "outputId": "70fe9b89-9698-4fcb-8557-e4936f16dbad"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weighted Sum from input layer :\n",
            " [[0.62 0.87]\n",
            " [0.54 1.17]\n",
            " [1.1  1.47]]\n",
            "Weighted Sum from hidden layer :\n",
            " [[0.88838755]\n",
            " [0.92374524]\n",
            " [0.9942182 ]]\n",
            "Input Data :\n",
            " [[0.5 0.3]\n",
            " [0.2 0.7]\n",
            " [0.8 0.9]]\n",
            "Output :\n",
            " [[0.70855731]\n",
            " [0.71580461]\n",
            " [0.72992029]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass without hidden layer (matrix multiplication) with Keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def forward_pass(x, epochs):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=1, activation='sigmoid', input_dim=2))  # Input to output\n",
        "    output = model.predict(x)\n",
        "    return output\n",
        "\n",
        "# Input data\n",
        "x = np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
        "\n",
        "# Output data\n",
        "output = forward_pass(x, epochs=100)\n",
        "\n",
        "print(\"\\nInput Data :\\n\", x)\n",
        "print(\"\\nOutput Data :\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Eu3v6A8Jqx_",
        "outputId": "87763fb1-628d-4c81-d590-e0bc95490c91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f569aee55a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 67ms/step\n",
            "\n",
            "Input Data :\n",
            " [[0.5 0.3]\n",
            " [0.2 0.7]\n",
            " [0.8 0.9]]\n",
            "\n",
            "Output Data :\n",
            " [[0.56770736]\n",
            " [0.4793672 ]\n",
            " [0.57377636]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward pass with hidden layer (matrix multiplication) with Keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def forward_pass(x, epochs):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(units=2, activation='sigmoid', input_dim=2))  # Input to hidden\n",
        "    model.add(Dense(units=1, activation='sigmoid'))  # Hidden to output\n",
        "    output = model.predict(x)\n",
        "    return output\n",
        "\n",
        "# Input data\n",
        "x = np.array([[0.5, 0.3], [0.2, 0.7], [0.8, 0.9]])\n",
        "\n",
        "# Output data\n",
        "output = forward_pass(x, epochs=100)  # Specify the number of epochs\n",
        "\n",
        "print(\"\\nInput Data :\\n\", x)\n",
        "print(\"\\nOutput Data :\\n\", output)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GCxomXhJuVI",
        "outputId": "16b69c6c-3463-4b82-8734-c61493a1e68d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 50ms/step\n",
            "\n",
            "Input Data :\n",
            " [[0.5 0.3]\n",
            " [0.2 0.7]\n",
            " [0.8 0.9]]\n",
            "\n",
            "Output Data :\n",
            " [[0.439917  ]\n",
            " [0.43961316]\n",
            " [0.4538533 ]]\n"
          ]
        }
      ]
    }
  ]
}